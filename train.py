import gensim
import pandas as pd
import smart_open
import random
import re
import logging
import numpy
from gensim.models import ldamodel
from gensim.corpora.dictionary import Dictionary

# The files (lda_tensor.tsv and lda_metadata.tsv) generated by this script can directly be uploaded to http://projector.tensorflow.org/ for visualization.

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# setting random seed to get the same results each time.
numpy.random.seed(1)

# read data
dataframe = pd.read_csv('movie_plots.csv')

# Convert data to required input format by LDA
texts = []
for line in dataframe.Plots:
    lowered = line.lower()
    words = re.findall(r'\w+', lowered, flags = re.UNICODE | re.LOCALE)
    texts.append(words)
dictionary = Dictionary(texts)
# Filter out words that occur less than 0 documents, or more than 30% of the documents.
dictionary.filter_extremes(no_below=0, no_above=0.3)
corpus = [dictionary.doc2bow(text) for text in texts]

# Set training parameters.
num_topics = 10
chunksize = 2000
passes = 20
iterations = 200
eval_every = True

# train model
model = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, chunksize=chunksize, alpha='auto', eta='auto', iterations=iterations, num_topics=num_topics, passes=passes, eval_every=eval_every)

# Get document topics
all_topics = model.get_document_topics(corpus, minimum_probability=0, per_word_topics=True)

tensors = []
# create file for tensors
with open('doc_lda_tensor.tsv','w') as w:
    for doc_topics, word_topics, phi_values in all_topics:
        doc_tensor = []
        for topics in doc_topics:
            doc_tensor.append(topics[1])
            w.write(str(topics[1])+ "\t")
        w.write("\n")
        tensors.append(doc_tensor)


# create file for metadata
i=0
with open('doc_lda_metadata.tsv','w') as w:
    w.write('Titles\tGenres\n')
    for j,k in zip(dataframe.Titles, dataframe.Genres):
        w.write("%s\t%s\n" % (''.join((str(j), str(tensors[i]))),k))
        i+=1

#  --------------------------------------------------------------------

# Plot word topics
topics = []
for i in range(len(model.id2word)):
    topics.append(model.get_term_topics(i,0))

# create file for tensors
with open('word_lda_tensor.tsv','w') as w:
    for t in topics:
        for ids in t:
            w.write(str(ids[1])+"\t")
        w.write("\n")

# create file for metadata
with open('word_lda_metadata.tsv','w') as w:
    for i in range(len(model.id2word)):
        w.write(model.id2word[i]+"\n")

